<p align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://img.shields.io/badge/Academic%20Assistant-CSV%20RAG-0b3d91?style=for-the-badge&logo=github&logoColor=white">
    <img alt="Academic Assistant (CSV RAG)" src="https://img.shields.io/badge/Academic%20Assistant-CSV%20RAG-1f6feb?style=for-the-badge&logo=github">
  </picture>
</p>

<h1 align="center">ğŸ“š Academic Assistant (CSVâ€‘based RAG)</h1>

<p align="center">
  A Retrievalâ€‘Augmented Generation (RAG) assistant for VIT University that answers student queries using
  <b>CSV</b> data â†’ <b>Chroma VectorDB</b> â†’ <b>Ollama (Llama2)</b> with <b>HuggingFace Embeddings</b>.
</p>

<p align="center">
  <a href="#-features"><img alt="Features" src="https://img.shields.io/badge/Features-9-10b981?style=flat-square"></a>
  <a href="#%EF%B8%8F-tech-stack"><img alt="Tech" src="https://img.shields.io/badge/Tech-Stack-6366f1?style=flat-square"></a>
  <a href="#%EF%B8%8F-installation"><img alt="Install" src="https://img.shields.io/badge/Install-Guide-22c55e?style=flat-square"></a>
  <a href="#-usage"><img alt="Usage" src="https://img.shields.io/badge/Usage-CLI-06b6d4?style=flat-square"></a>
  <a href="#-project-structure"><img alt="Tree" src="https://img.shields.io/badge/Project-Tree-f59e0b?style=flat-square"></a>
  <a href="#-contributing"><img alt="Contrib" src="https://img.shields.io/badge/PRs-Welcome-f472b6?style=flat-square"></a>
  <a href="#-license"><img alt="License" src="https://img.shields.io/badge/License-MIT-111827?style=flat-square"></a>
</p>

---

## âœ¨ Overview

This project implements a **CSVâ€‘powered RAG assistant** for academic data (courses, subjects, credits, prerequisites,
labs, electives, etc.). It uses **Chroma** as a vector store, **Alibaba-NLP gte-large-en-v1.5** embeddings for semantic
search, and **Ollama (Llama2)** to generate structured, studentâ€‘friendly answers. The assistant avoids hallucinations
and will reply with **â€œI donâ€™t knowâ€** when data is missing.

> Bonus: Optional **AGNO Agent** integration with **Gemini + Reasoning Tools** to orchestrate complex tool use.

## ğŸš€ Features

* âœ… Load academic data from a **CSV** into **Chroma VectorDB**
* âœ… Use **Alibabaâ€‘NLP `gte-large-en-v1.5`** embeddings for semantic search
* âœ… Retrieve chunks with **`RecursiveCharacterTextSplitter`** (LangChain)
* âœ… Generate answers with **Ollama (Llama2 local LLM)**
* âœ… Accuracyâ€‘first: gracefully answers **â€œI donâ€™t knowâ€** if the data is missing
* âœ… Outputs **tables** and neat formatting when possible
* âœ… Optional **AGNO Agent** with **Gemini + Reasoning Tools**

## ğŸ§  RAG Flow (Mermaid)

```mermaid
flowchart LR
  A[CSV Dataset\nresult.csv] -->|Load & Clean| B[Chunking\nRecursiveCharacterTextSplitter]
  B --> C[Embedding\nAlibaba-NLP gte-large-en-v1.5]
  C --> D[Chroma VectorDB]
  E[User Query] --> F[Retriever]
  F --> D
  D -->|Topâ€‘K Chunks| G[LLM: Ollama (Llama2)]
  G --> H[Structured Answer\n(tables, citations, \"I don't know\")]
  subgraph Optional Agent Layer
    I[AGNO Agent] --> F
    I --> G
  end
```

## ğŸ› ï¸ Tech Stack

<p>
  <img alt="Python" src="https://img.shields.io/badge/Python-3.9%2B-3776AB?logo=python&logoColor=white">
  <img alt="LangChain" src="https://img.shields.io/badge/LangChain-Tooling-1a7f37?logo=chainlink&logoColor=white">
  <img alt="Chroma" src="https://img.shields.io/badge/Chroma-VectorDB-8b5cf6">
  <img alt="HuggingFace" src="https://img.shields.io/badge/HuggingFace-Embeddings-ffcc00?logo=huggingface&logoColor=black">
  <img alt="Ollama" src="https://img.shields.io/badge/Ollama-Llama2-0ea5e9">
  <img alt="dotenv" src="https://img.shields.io/badge/dotenv-Config-4ade80">
  <img alt="AGNO" src="https://img.shields.io/badge/AGNO-Optional-f97316">
</p>

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ resources/
â”‚   â””â”€â”€ academics/         # Chroma vectorstore directory
â”œâ”€â”€ result.csv             # CSV dataset with academic information
â”œâ”€â”€ academic_assistant.py  # Main script
â””â”€â”€ README.md              # Documentation
```

## âš™ï¸ Installation

> Replace `yourusername/academic-assistant` with your GitHub handle and repository name.

```bash
# 1) Clone the repository
git clone https://github.com/yourusername/academic-assistant.git
cd academic-assistant

# 2) Create & activate a virtual environment
python3 -m venv venv
# Mac/Linux
source venv/bin/activate
# Windows (PowerShell)
venv\Scripts\Activate.ps1

# 3) Install dependencies
pip install -r requirements.txt

# 4) Install Ollama (for local Llama2)
#   â€“ macOS:  https://ollama.com/download
#   â€“ Linux:  curl -fsSL https://ollama.com/install.sh | sh
#   â€“ Windows: https://ollama.com/download

# 5) Pull the Llama2 model
ollama pull llama2
```

### ğŸ” Environment Variables

Create a `.env` file in the project root:

```dotenv
# Avoids tokenizer parallelism warnings
TOKENIZERS_PARALLELISM=false
```

> If you add keys for optional services (e.g., Gemini for AGNO Agent), document them here too.

## â–¶ï¸ Usage

```bash
# Index the CSV and start answering queries
python academic_assistant.py --csv ./result.csv --persist ./resources/academics

# Example flags (customize as needed)
# --k 4                         # top-k chunks to retrieve
# --model llama2                # Ollama model name
# --embedding gte-large-en-v1.5 # embedding model id
# --max-tokens 512              # generation cap
```

<details>
  <summary><b>Sample Query</b></summary>

```text
User: What are the prerequisites for CSE2004 and how many credits is it?
Assistant:
- Course: CSE2004 â€” Data Structures
- Credits: 4
- Prerequisites: CSE1001 or equivalent foundation (per CSV row #42)
```

</details>

## ğŸ“Š Output Format

* Answers are **factâ€‘grounded** in the CSV (citationâ€‘style references to row/field when possible)
* Uses **tables** for course lists and **bullet points** for requirements
* If information is not in the dataset, responds with **â€œI donâ€™t knowâ€**

> Example Table (rendered by the assistant):

| Course Code | Title            | Credits | Prerequisites   |
| ----------- | ---------------- | ------- | --------------- |
| CSE2004     | Data Structures  | 4       | CSE1001         |
| CSE3001     | Machine Learning | 3       | Probability, DS |

## ğŸ§ª Development Notes

* The first run will **create/persist** a Chroma DB under `./resources/academics/`
* Reâ€‘index if `result.csv` changes (or implement file hashing to autoâ€‘refresh)
* Prefer **deterministic** prompts and **topâ€‘k** tuning for reliability

## ğŸ§© Optional: AGNO Agent + Gemini

If you enable the AGNO Agent orchestration layer, you can:

* Route queries through **tools** (e.g., tabular filtering, CSV aggregation)
* Use **Gemini + Reasoning Tools** for complex planning
* Keep Ollama/Llama2 as the final answer generator

> Add any required keys to `.env` and document your agent config under `./agents/`.

## ğŸ› Troubleshooting

* **Ollama not found** â†’ install from the official site and ensure the daemon is running
* **Model missing** â†’ run `ollama pull llama2`
* **Tokenizer warnings** â†’ ensure `TOKENIZERS_PARALLELISM=false` in `.env`
* **Slow/empty retrievals** â†’ check CSV cleanliness, chunk size/overlap, and embedding model id

## ğŸ¤ Contributing

PRs welcome! Please:

1. Fork the repo
2. Create a feature branch (`feat/my-awesome-thing`)
3. Commit with conventional messages
4. Open a PR with screenshots or terminal output

## ğŸ§­ Roadmap

* [ ] Add evaluation suite (answer faithfulness & coverage)
* [ ] Web UI (FastAPI + React) for student queries
* [ ] Better table rendering + column alignment
* [ ] Multiâ€‘CSV ingestion (departmentâ€‘wise)
* [ ] Dockerfile & CI (GitHub Actions)

## ğŸ“œ License

Distributed under the **MIT License**. See `LICENSE` for details.

---

<p align="center">
  Built with â¤ï¸ for students | Maintained by <a href="https://github.com/yourusername">@yourusername</a>
</p>
